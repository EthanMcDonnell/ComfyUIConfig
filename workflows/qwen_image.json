{
  "id": "91f6bbe2-ed41-4fd6-bac7-71d5b5864ecb",
  "revision": 0,
  "last_node_id": 85,
  "last_link_id": 140,
  "nodes": [
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [20, 340],
      "size": [330, 60],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [76]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "qwen_image_vae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors",
            "directory": "vae"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": ["qwen_image_vae.safetensors"]
    },
    {
      "id": 38,
      "type": "CLIPLoader",
      "pos": [20, 190],
      "size": [330, 110],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 0,
          "links": [74, 75]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPLoader",
        "models": [
          {
            "name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "directory": "text_encoders"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "qwen_2.5_vl_7b_fp8_scaled.safetensors",
        "qwen_image",
        "default"
      ]
    },
    {
      "id": 69,
      "type": "MarkdownNote",
      "pos": [-540, -220],
      "size": [390, 180],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "VRAM Usage",
      "properties": {
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "## GPU:RTX4090D 24GB\n\n| Configuration            | VRAM Usage | 1st Generation | 2nd Generation |\n|---------------------|---------------|---------------|-----------------|\n| Fp8_e4m3fn             | 86%                | â‰ˆ 94s               | â‰ˆ 71s                   |\n| With 8steps LoRA    | 86%                | â‰ˆ 55s               | â‰ˆ 34s                  |\n| Distill fp8_e4m3fn   | 86%                | â‰ˆ 69s               | â‰ˆ 36s                  |"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 70,
      "type": "Note",
      "pos": [850, 910],
      "size": [310, 120],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "For fp8 without 8steps LoRA",
      "properties": {},
      "widgets_values": [
        "Set cfg to 1.0 for a speed boost at the cost of consistency. Samplers like res_multistep work pretty well at cfg 1.0\n\nThe official number of steps is 50 but I think that's too much. Even just 10 steps seems to work."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 74,
      "type": "MarkdownNote",
      "pos": [850, 660],
      "size": [310, 210],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "KSampler settings",
      "properties": {},
      "widgets_values": [
        "You can test and find the best setting by yourself. The following table is for reference.\n\n| model            | steps | cfg |\n|---------------------|---------------|---------------|\n| fp8_e4m3fnï¼ˆQwen team's suggestionï¼‰             | 40                | 2.5               \n| fp8_e4m3fn             | 20                | 2.5               |\n| fp8_e4m3fn + 8steps LoRA    | 8               | 1.0               |\n| distill fp8_e4m3fn   | 10               | 1.0              |"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 67,
      "type": "MarkdownNote",
      "pos": [-540, 10],
      "size": [540, 630],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model links",
      "properties": {
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "[Tutorial](https://docs.comfy.org/tutorials/image/qwen/qwen-image) \n\n## Model links\n\nYou can find all the models on [Huggingface](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/tree/main) or [Modelscope](https://modelscope.cn/models/Comfy-Org/Qwen-Image_ComfyUI/files)\n\n**Diffusion model**\n\n- [qwen_image_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors)\n\nQwen_image_distill\n\n- [qwen_image_distill_full_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/non_official/diffusion_models/qwen_image_distill_full_fp8_e4m3fn.safetensors)\n- [qwen_image_distill_full_bf16.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/non_official/diffusion_models/qwen_image_distill_full_bf16.safetensors)\n\n**LoRA**\n\n- [Qwen-Image-Lightning-8steps-V1.0.safetensors](https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V1.0.safetensors)\n\n**Text encoder**\n\n- [qwen_2.5_vl_7b_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors)\n\n**VAE**\n\n- [qwen_image_vae.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors)\n\nModel Storage Location\n\n```\nðŸ“‚ ComfyUI/\nâ”œâ”€â”€ ðŸ“‚ models/\nâ”‚   â”œâ”€â”€ ðŸ“‚ diffusion_models/\nâ”‚   â”‚   â”œâ”€â”€ qwen_image_fp8_e4m3fn.safetensors\nâ”‚   â”‚   â””â”€â”€ qwen_image_distill_full_fp8_e4m3fn.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ loras/\nâ”‚   â”‚   â””â”€â”€ Qwen-Image-Lightning-8steps-V1.0.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ vae/\nâ”‚   â”‚   â””â”€â”€ qwen_image_vae.safetensors\nâ”‚   â””â”€â”€ ðŸ“‚ text_encoders/\nâ”‚       â””â”€â”€ qwen_2.5_vl_7b_fp8_scaled.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 66,
      "type": "ModelSamplingAuraFlow",
      "pos": [850, 10],
      "size": [300, 58],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 132
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [125]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "ModelSamplingAuraFlow",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [1.3]
    },
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [20, 50],
      "size": [330, 90],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [131]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "qwen_image_fp8_e4m3fn.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors",
            "directory": "diffusion_models"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": ["qwen_image_fp8_e4m3fn.safetensors", "default"]
    },
    {
      "id": 60,
      "type": "SaveImage",
      "pos": [1993.788430190375, 37.977720270616416],
      "size": [490, 600],
      "flags": {},
      "order": 20,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 140
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "SaveImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": ["ComfyUI"]
    },
    {
      "id": 81,
      "type": "Image Chromatic Aberration",
      "pos": [1458.0587952118399, -16.98046218251113],
      "size": [350, 160],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 139
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [136]
        }
      ],
      "properties": {
        "aux_id": "ltdrdata/was-node-suite-comfyui",
        "ver": "9ae952b1b435d2bd846bfe6516919b5a8b9201aa",
        "Node name for S&R": "Image Chromatic Aberration",
        "cnr_id": "pr-was-node-suite-comfyui-47064894",
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {
            "red_offset": true,
            "green_offset": true,
            "blue_offset": true,
            "intensity": true,
            "fade_radius": true
          }
        }
      },
      "widgets_values": [0, 0, 1, 0.17, 4],
      "shape": 1
    },
    {
      "id": 82,
      "type": "Image Lucy Sharpen",
      "pos": [1458.0587952118399, 193.01953781748924],
      "size": [350.9100646972656, 82],
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 136
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [137]
        }
      ],
      "properties": {
        "aux_id": "ltdrdata/was-node-suite-comfyui",
        "ver": "9ae952b1b435d2bd846bfe6516919b5a8b9201aa",
        "Node name for S&R": "Image Lucy Sharpen",
        "cnr_id": "pr-was-node-suite-comfyui-47064894",
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {
            "iterations": true,
            "kernel_size": true
          }
        }
      },
      "widgets_values": [1, 1],
      "shape": 1
    },
    {
      "id": 83,
      "type": "Image Bloom Filter",
      "pos": [1458.0587952118399, 323.0195378174892],
      "size": [349.7084655761719, 82],
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 137
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [138]
        }
      ],
      "properties": {
        "aux_id": "ltdrdata/was-node-suite-comfyui",
        "ver": "9ae952b1b435d2bd846bfe6516919b5a8b9201aa",
        "Node name for S&R": "Image Bloom Filter",
        "cnr_id": "pr-was-node-suite-comfyui-47064894",
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {
            "radius": true,
            "intensity": true
          }
        }
      },
      "widgets_values": [6, 0.3],
      "shape": 1
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [1170, -90],
      "size": [210, 46],
      "flags": {
        "collapsed": false
      },
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 128
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 76
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [139]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAEDecode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": []
    },
    {
      "id": 58,
      "type": "EmptySD3LatentImage",
      "pos": [50, 510],
      "size": [270, 106],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [107]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "EmptySD3LatentImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [1024, 1024, 1]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [968.8791422179445, 132.52180750373483],
      "size": [300, 474],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 125
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 46
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 52
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 107
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [128]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "KSampler",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        354611591421565,
        "randomize",
        40,
        2.5,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [390, 440],
      "size": [425.27801513671875, 180.6060791015625],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 75
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [52]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "low quality, blurry, bad anatomy, deformed,extra fingers, missing limbs, malformed hands, cartoonish, watermark, cinematic, glossy finish, shallow depth of field, cinematic bokeh, uncanny anatomy, frame-perfect symmetry, blurred background, fat, low resolution"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 71,
      "type": "Note",
      "pos": [849.0348909396324, -151.8485989921186],
      "size": [300, 88],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "Increase the shift if you get too many blury/dark/bad images. Decrease if you want to try increasing detail."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [390, 240],
      "size": [422.84503173828125, 164.31304931640625],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 74
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [46]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "am0rgn, 1girl, \n\nFemale subject, medium shot mirror selfie, crouching down low in an indoor setting. The subject wears a black tank top and loose-fitting, wide-legged blue denim jeans. She wears white wireless earbuds, a thin silver necklace with a large round pendant, multiple silver bracelets, and silver rings on her right hand. Her nails are painted dark brown or black. Cleavage\n\nShe holds a black smartphone in her right hand, positioned in front of her face, with a small photo visible on the back of the phone case. Her left hand touches her chin.\n\nThe background shows a light pink wall, a dark wooden door with a silver handle on the right, and a tv mounted on the wall to the left. The floor is tiled with light beige or cream tiles. Artificial indoor lighting illuminates the scene, casting a slight glow on the subject's forehead. The camera angle is straight on"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 85,
      "type": "Note",
      "pos": [422.28594262869245, -218.43064107456027],
      "size": [313.71963086610026, 88],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": ["amorgan, 1girl, samsung\n0.8, 0, 0.7\n1, 0, 0.2"],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 84,
      "type": "Film Grain",
      "pos": [1458.0587952118399, 463.0005864014717],
      "size": [350, 154],
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 138
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [140]
        }
      ],
      "properties": {
        "aux_id": "ClownsharkBatwing/RES4LYF",
        "ver": "7750bf7800b6ad9d670308a09989fc0c04c40cec",
        "Node name for S&R": "Film Grain",
        "cnr_id": "RES4LYF",
        "ue_properties": {
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {},
          "version": "7.2"
        }
      },
      "widgets_values": [1, 0.07, 1, 5, 1],
      "shape": 1
    },
    {
      "id": 76,
      "type": "Power Lora Loader (rgthree)",
      "pos": [432.9804418896122, -63.13281732128905],
      "size": [324.82119140625, 190],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "dir": 3,
          "name": "model",
          "type": "MODEL",
          "link": 131
        },
        {
          "dir": 3,
          "name": "clip",
          "type": "CLIP",
          "link": null
        }
      ],
      "outputs": [
        {
          "dir": 4,
          "name": "MODEL",
          "shape": 3,
          "type": "MODEL",
          "links": [132]
        },
        {
          "dir": 4,
          "name": "CLIP",
          "shape": 3,
          "type": "CLIP",
          "links": null
        }
      ],
      "properties": {
        "aux_id": "rgthree/rgthree-comfy",
        "ver": "67c3ba1b7c406d3d935a775e0d118a718b219868",
        "Show Strengths": "Single Strength",
        "cnr_id": "rgthree-comfy"
      },
      "widgets_values": [
        {},
        {
          "type": "PowerLoraLoaderHeaderWidget"
        },
        {
          "on": true,
          "lora": "am0rgn-qwen-lora_000002500.safetensors",
          "strength": 1,
          "strengthTwo": null
        },
        {
          "on": true,
          "lora": "1GIRL_QWEN_V3.safetensors",
          "strength": 0.2,
          "strengthTwo": null
        },
        {
          "on": true,
          "lora": "Samsung.safetensors",
          "strength": 0.2,
          "strengthTwo": null
        },
        {},
        ""
      ]
    }
  ],
  "links": [
    [46, 6, 0, 3, 1, "CONDITIONING"],
    [52, 7, 0, 3, 2, "CONDITIONING"],
    [74, 38, 0, 6, 0, "CLIP"],
    [75, 38, 0, 7, 0, "CLIP"],
    [76, 39, 0, 8, 1, "VAE"],
    [107, 58, 0, 3, 3, "LATENT"],
    [125, 66, 0, 3, 0, "MODEL"],
    [128, 3, 0, 8, 0, "LATENT"],
    [131, 37, 0, 76, 0, "MODEL"],
    [132, 76, 0, 66, 0, "MODEL"],
    [136, 81, 0, 82, 0, "IMAGE"],
    [137, 82, 0, 83, 0, "IMAGE"],
    [138, 83, 0, 84, 0, "IMAGE"],
    [139, 8, 0, 81, 0, "IMAGE"],
    [140, 84, 0, 60, 0, "IMAGE"]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step1 - Load models",
      "bounding": [10, -20, 350, 433.6000061035156],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step2 - Image size",
      "bounding": [10, 430, 350, 210],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step3 - Prompt",
      "bounding": [380, 160, 450, 470],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "POST PROCESSING",
      "bounding": [1438.0587952118399, -96.98046218251118, 390, 730],
      "color": "#e73168",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.8563242382962116,
      "offset": [503.2316352334506, 283.11828959345974]
    },
    "frontendVersion": "1.28.8",
    "ue_links": [],
    "links_added_by_ue": [],
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}
