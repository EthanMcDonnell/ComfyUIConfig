{
  "id": "0de6c257-d141-4418-8acf-edee3afa3fd3",
  "revision": 0,
  "last_node_id": 19,
  "last_link_id": 19,
  "nodes": [
    {
      "id": 3,
      "type": "CLIPTextEncode",
      "pos": [1761, 870],
      "size": [425.27801513671875, 180.6060791015625],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 2
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [10]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [""],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 4,
      "type": "MarkdownNote",
      "pos": [831, 210],
      "size": [390, 180],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "VRAM Usage",
      "properties": {
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "## GPU:RTX4090D 24GB\n\n| Configuration            | VRAM Usage | 1st Generation | 2nd Generation |\n|---------------------|---------------|---------------|-----------------|\n| Fp8_e4m3fn             | 86%                | â‰ˆ 94s               | â‰ˆ 71s                   |\n| With 8steps LoRA    | 86%                | â‰ˆ 55s               | â‰ˆ 34s                  |\n| Distill fp8_e4m3fn   | 86%                | â‰ˆ 69s               | â‰ˆ 36s                  |"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 5,
      "type": "Note",
      "pos": [2221, 310],
      "size": [300, 88],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "Increase the shift if you get too many blury/dark/bad images. Decrease if you want to try increasing detail."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 6,
      "type": "Note",
      "pos": [2221, 1340],
      "size": [310, 120],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "For fp8 without 8steps LoRA",
      "properties": {},
      "widgets_values": [
        "Set cfg to 1.0 for a speed boost at the cost of consistency. Samplers like res_multistep work pretty well at cfg 1.0\n\nThe official number of steps is 50 but I think that's too much. Even just 10 steps seems to work."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 7,
      "type": "MarkdownNote",
      "pos": [831, 440],
      "size": [540, 630],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model links",
      "properties": {
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "[Tutorial](https://docs.comfy.org/tutorials/image/qwen/qwen-image) \n\n## Model links\n\nYou can find all the models on [Huggingface](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/tree/main) or [Modelscope](https://modelscope.cn/models/Comfy-Org/Qwen-Image_ComfyUI/files)\n\n**Diffusion model**\n\n- [qwen_image_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors)\n\nQwen_image_distill\n\n- [qwen_image_distill_full_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/non_official/diffusion_models/qwen_image_distill_full_fp8_e4m3fn.safetensors)\n- [qwen_image_distill_full_bf16.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/non_official/diffusion_models/qwen_image_distill_full_bf16.safetensors)\n\n**LoRA**\n\n- [Qwen-Image-Lightning-8steps-V1.0.safetensors](https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V1.0.safetensors)\n\n**Text encoder**\n\n- [qwen_2.5_vl_7b_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors)\n\n**VAE**\n\n- [qwen_image_vae.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors)\n\nModel Storage Location\n\n```\nðŸ“‚ ComfyUI/\nâ”œâ”€â”€ ðŸ“‚ models/\nâ”‚   â”œâ”€â”€ ðŸ“‚ diffusion_models/\nâ”‚   â”‚   â”œâ”€â”€ qwen_image_fp8_e4m3fn.safetensors\nâ”‚   â”‚   â””â”€â”€ qwen_image_distill_full_fp8_e4m3fn.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ loras/\nâ”‚   â”‚   â””â”€â”€ Qwen-Image-Lightning-8steps-V1.0.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ vae/\nâ”‚   â”‚   â””â”€â”€ qwen_image_vae.safetensors\nâ”‚   â””â”€â”€ ðŸ“‚ text_encoders/\nâ”‚       â””â”€â”€ qwen_2.5_vl_7b_fp8_scaled.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 8,
      "type": "CLIPLoader",
      "pos": [1391, 620],
      "size": [330, 110],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 0,
          "links": [1, 2]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPLoader",
        "models": [
          {
            "name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "directory": "text_encoders"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "qwen_2.5_vl_7b_fp8_scaled.safetensors",
        "qwen_image",
        "default"
      ]
    },
    {
      "id": 9,
      "type": "UNETLoader",
      "pos": [1391, 480],
      "size": [330, 90],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [3]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "qwen_image_fp8_e4m3fn.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors",
            "directory": "diffusion_models"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": ["qwen_image_fp8_e4m3fn.safetensors", "default"]
    },
    {
      "id": 10,
      "type": "MarkdownNote",
      "pos": [1816.210466215639, 1246.398277847411],
      "size": [310, 210],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "KSampler settings",
      "properties": {},
      "widgets_values": [
        "You can test and find the best setting by yourself. The following table is for reference.\n\n| model            | steps | cfg |\n|---------------------|---------------|---------------|\n| fp8_e4m3fnï¼ˆQwen team's suggestionï¼‰             | 40                | 2.5               \n| fp8_e4m3fn             | 20                | 2.5               |\n| fp8_e4m3fn + 8steps LoRA    | 8               | 1.0               |\n| distill fp8_e4m3fn   | 10               | 1.0              |"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 11,
      "type": "LoraLoaderModelOnly",
      "pos": [1804.225323867703, 486.70655227826046],
      "size": [270, 82],
      "flags": {},
      "order": 12,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 3
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [13]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.49",
        "Node name for S&R": "LoraLoaderModelOnly",
        "models": [
          {
            "name": "Qwen-Image-Lightning-8steps-V1.0.safetensors",
            "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V1.0.safetensors",
            "directory": "loras"
          }
        ]
      },
      "widgets_values": ["Qwen-Image-Lightning-8steps-V1.0.safetensors", 1]
    },
    {
      "id": 18,
      "type": "Power Lora Loader (rgthree)",
      "pos": [2222.1920000000005, 443.9930000000002],
      "size": [324.82119140625, 118],
      "flags": {},
      "order": 14,
      "mode": 4,
      "inputs": [
        {
          "dir": 3,
          "name": "model",
          "type": "MODEL",
          "link": 13
        },
        {
          "dir": 3,
          "name": "clip",
          "type": "CLIP",
          "link": null
        }
      ],
      "outputs": [
        {
          "dir": 4,
          "name": "MODEL",
          "shape": 3,
          "type": "MODEL",
          "links": [14]
        },
        {
          "dir": 4,
          "name": "CLIP",
          "shape": 3,
          "type": "CLIP",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "rgthree-comfy",
        "ver": "2b9eb36d3e1741e88dbfccade0e08137f7fa2bfb",
        "Show Strengths": "Single Strength",
        "aux_id": "rgthree/rgthree-comfy"
      },
      "widgets_values": [
        {},
        {
          "type": "PowerLoraLoaderHeaderWidget"
        },
        {},
        ""
      ]
    },
    {
      "id": 1,
      "type": "EmptySD3LatentImage",
      "pos": [1421, 940],
      "size": [270, 106],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [17]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "EmptySD3LatentImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [1328, 1328, 1]
    },
    {
      "id": 14,
      "type": "VAEDecode",
      "pos": [2744.720377766702, 458.52932637326086],
      "size": [210, 46],
      "flags": {
        "collapsed": false
      },
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 4
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 5
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [12]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAEDecode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": []
    },
    {
      "id": 15,
      "type": "VAEEncode",
      "pos": [2571.031544626055, 454.84156329256956],
      "size": [140, 46],
      "flags": {},
      "order": 13,
      "mode": 4,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 18
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 19
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": []
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.66",
        "Node name for S&R": "VAEEncode"
      },
      "widgets_values": []
    },
    {
      "id": 12,
      "type": "LoadImage",
      "pos": [2267.0338850536227, 777.6519334739855],
      "size": [274.080078125, 314.00000000000006],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [18]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.66",
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": ["example.png", "image"]
    },
    {
      "id": 13,
      "type": "VAELoader",
      "pos": [1391, 770],
      "size": [330, 60],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [5, 19]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "qwen_image_vae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors",
            "directory": "vae"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": ["qwen_image_vae.safetensors"]
    },
    {
      "id": 2,
      "type": "CLIPTextEncode",
      "pos": [1761, 670],
      "size": [422.84503173828125, 164.31304931640625],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 1
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [9]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "portrait, masterpiece, 4k, ray tracing, intricate details, highly-detailed, hyper-realistic, 8k RAW Editorial Photo.1girl, solo, blush, short hair, simple background, shirt, black hair, dress, bow, closed mouth, upper body, hair bow, hairband, blunt bangs, black dress, black eyes, black shirt, looking to the side, bob cut, yellow background, yellow bow, pinafore dress, yellow hairband, Flatline,cinematic light, dramatic light, shallow depth of field,  high budget, bokeh, cinemascope, film grain,"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 16,
      "type": "KSampler",
      "pos": [2620.5778549312804, 650.5298112780985],
      "size": [300, 474],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 8
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 9
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 10
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 17
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [4]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "KSampler",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        222518378103538,
        "randomize",
        40,
        2.5,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 17,
      "type": "SaveImage",
      "pos": [2991.9156493903165, 450.6852049618558],
      "size": [490, 600],
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 12
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "SaveImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": ["ComfyUI"]
    },
    {
      "id": 19,
      "type": "ModelSamplingAuraFlow",
      "pos": [2280.1448810637457, 637.3161010120858],
      "size": [300, 58],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 14
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [8]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "ModelSamplingAuraFlow",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [1]
    }
  ],
  "links": [
    [1, 8, 0, 2, 0, "CLIP"],
    [2, 8, 0, 3, 0, "CLIP"],
    [3, 9, 0, 11, 0, "MODEL"],
    [4, 16, 0, 14, 0, "LATENT"],
    [5, 13, 0, 14, 1, "VAE"],
    [8, 19, 0, 16, 0, "MODEL"],
    [9, 2, 0, 16, 1, "CONDITIONING"],
    [10, 3, 0, 16, 2, "CONDITIONING"],
    [12, 14, 0, 17, 0, "IMAGE"],
    [13, 11, 0, 18, 0, "MODEL"],
    [14, 18, 0, 19, 0, "MODEL"],
    [17, 1, 0, 16, 3, "LATENT"],
    [18, 12, 0, 15, 0, "IMAGE"],
    [19, 13, 0, 15, 1, "VAE"]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step1 - Load models",
      "bounding": [1381, 410, 350, 433.6000061035156],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step2 - Image size",
      "bounding": [1381, 860, 350, 210],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step3 - Prompt",
      "bounding": [1751, 590, 450, 470],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "Lightx2v 8steps LoRA",
      "bounding": [1751, 410, 450, 170],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.8264462809917354,
      "offset": [-1220.4722036793748, -260.51467673877175]
    },
    "frontendVersion": "1.28.7"
  },
  "version": 0.4
}
